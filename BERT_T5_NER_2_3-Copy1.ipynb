{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>A Simple Named Entity Recognition Model using  BERT  and Keras </center></h1>\n",
    "    \n",
    "<h2><center>    (And Another Simple One Using T5)</center></h2>\n",
    "<h4><center>Initially prepared for UC Berkeley MIDS - W266</center></h4>\n",
    "\n",
    "\n",
    "<h3><center>SUMMARY</center></h3>\n",
    "\n",
    "In this notebook we investigate how we can leverage **BERT** (see [\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"](https://arxiv.org/pdf/1810.04805.pdf), by Devlin/Chang/Lee/Toutanova, Google AI Language) for the problem of Named Entity Recognition (NER). Their paper actually contains the NER use case as a fine-tuning example, but we are not striving to replicate necessarily exactly their approach but build the model in the most approachable and 'naive' way, i.e. simply applying a straightforward model that follows intuitively the BERT mantra leveraging its context-based embeddings.\n",
    "\n",
    "\n",
    "We look at the effect of also fine-tuning BERT layers vs just adding and training classification layers on top of the BERT model and find that in this cursory and certainly incomplete study the re-training of BERT layers does offer some advantages. We also perform a test reducing the training data by 90% and find that the results are still quite decent, re-emphasizing BERT's usefulness in situations where the data set is on the small side. \n",
    "\n",
    "**Update:** In the appendix, we also recast the NER problem as a 'translation problem', allowing us to also get some practice with **T5** [\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"](https://arxiv.org/pdf/1910.10683.pdf) , by C. Raffel et al. (Note that one likely would expect less favorable results for the specific NER problem, but the introduction of T5 is the purpose, not the actual result.)\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "I. [Introduction & Approach](#ia)   \n",
    "1. [Introduction](#intro)  \n",
    "2. [Problem Definition & Metrics](#problem)  \n",
    "3. [Notebook Strategy](#strategy)  \n",
    "\n",
    "\n",
    "II. [Setup](#setup)   \n",
    "1. [Data](#data)  \n",
    "2. [BERT](#bert)  \n",
    "3. [Getting Started](#start)  \n",
    "\n",
    "\n",
    "III. [Data Preprocessing](#preprocess)   \n",
    "1. [BERT Tokenizer](#tokenizer)  \n",
    "2. [Extraction](#extract)  \n",
    "3. [Initial Data Analysis](#analysis) \n",
    "4. [Baseline: Always picking 'Other'](#baseline) \n",
    "5. [Train/Test Split](#split)  \n",
    "\n",
    "IV. [The Model](#model)   \n",
    "1. [Custom Loss & Accuracy](#custom)  \n",
    "2. [BERT Layer](#bert_layer)  \n",
    "2. [Model Construction](#ner_model) \n",
    "\n",
    "\n",
    "V. [Model Runs/Experiments](#runs)   \n",
    "1. [With BERT-layer Fine-Tuning](#retrain)  \n",
    "2. [Predictions & Confusion Matrix](#confusion)  \n",
    "3. [Without BERT-Layer Fine-Tuning](#basic)  \n",
    "4. [A 90%-Reduced Training Set](#tiny)  \n",
    "\n",
    "\n",
    "VI. [Summary](#summary)  \n",
    "\n",
    "Appendix: [T5](#T5)  \n",
    "\n",
    "\n",
    "\n",
    "## I. Introduction & Approach <a id=\"ia\" />\n",
    "\n",
    "### I. Introduction & Strategy <a id=\"intro\" />\n",
    "\n",
    "BERT and other context-aware embedding frameworks like [ELMO](https://arxiv.org/abs/1802.05365), OpenAI's [GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf), and [XLNet](https://arxiv.org/pdf/1906.08237.pdf), etc.  -  provide extremely useful basis for many NLP tasks. A key reason why these frameworks are so useful is that they allow us to use the power of extensive pre-training that was done on a (set of) large corpus/era. \n",
    "\n",
    "More specifically, their ability to encode deep contextual relationships between words (and sentences or sentence segments) derived from a generic set of tasks provides us with the context-specific embeddings.  Depending on the task, we can then simply add a couple of classification layers with a modest number of weights to fine-tune the combined model to our very specific NLP task that may not have the luxury of a very large labeled data set.\n",
    "\n",
    "There are numerous and very good resources available on the web for various of these tasks (Movie Reviews, Sentiment  Analysis, etc,.). In this notebook, we want to consider the task of Named Entity Recognition, as it features a number of useful complexities that are good to discuss:\n",
    "\n",
    "* token-level vs. sentence-level BERT output, which seems to be less-often discussed \n",
    "* potential one-to-many split of word-to-token by the tokenizer (what are we going to do for the labels?) \n",
    "* potentially a need for custom loss and accuracy definitions\n",
    "\n",
    "Conceptually, we will follow the original BERT paper in its approach to NER:\n",
    "\n",
    "<img src=\"BERT_NER_Devlin_et_al.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<center>Image Source: \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\"</center>\n",
    "\n",
    "Each word will need to be tokenized. We will then, sentence-by-sentence, feed in the tokenized text into BERT, resulting in our case (we are using the BERT's base model) in a 768-dimensional output vector for each input token (and other tokens that BERT wants us to add). We then simply add a fully-connected hidden layer and finally a classification of suitable dimension that will take each token-output and make a decision on its NER label.  \n",
    "\n",
    "\n",
    "This is very intuitive. However, a few obvious questions arise that we want to look at in this notebook:\n",
    "\n",
    "1) How do we need to pre-process the data set to be suitable for BERT?   \n",
    "3) How can we build the model in Keras?   \n",
    "4) How can we incorporate custom loss functions and accuracy calculations?   \n",
    "5) What does fine-tuning mean? Is it just adding and training new layer(s), or do I re-train BERT layers as well?   \n",
    "6) Do I need to worry about customizing the optimizer?  \n",
    "\n",
    "These and other questions we hope to be able to shed some light on. The dataset we will be using is the \"**Annotated Corpus for Named Entity Recognition using GMB [Groningen Meaning Bank]**\", which is shared on [Kaggle](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus). It contains sentences with 1m+ words, conveniently annotated with POS and NER tags. \n",
    "\n",
    "### I.2. Problem Definition & Metrics <a id=\"problem\" />\n",
    "\n",
    "Our task will obviously be to properly identify the NER tags. There are potentially two things to consider when we want to define our success metrics: \n",
    "\n",
    "1) If we send the data sentence-by-sentence, we will need to apply padding to ensure consistent length. This will create 'new' labels that we will call 'nerPad'. Also, words can be split into multiple tokens, requiring us to add filler labels, which we will denote 'nerX'.  (There are multiple ways to address this, but this is what we are choosing here.)\n",
    "\n",
    "If we do that, should we look at accuracy over all tokens? Probably not. So our **first metric will be: accuracy for tokens which were part of the original text (and only the first token if a word is split)**.\n",
    "\n",
    "2) As we know from NER problems, most tokens will be 'Other'. So we may get already a pretty decent baseline result by always predicting 'Other'. In situations like that it may be useful to also look at **our second metric: the accuracy for all original tokens that are not 'Other'**.\n",
    "\n",
    "\n",
    "### I.3. Notebook Strategy <a id=\"strategy\" />\n",
    "\n",
    "The outline that we will follow in this notebook is this:\n",
    "\n",
    "**1) Process the text**\n",
    "* re-assemble words into sentences. (The corpus is of the form one-line-one-word, with sentence markers.)\n",
    "* tokenize the sentences with the BERT Tokenizer\n",
    "* create the input ids required for BERT:\n",
    "   * **sentence_ids** [the list of token ids for each sentence]\n",
    "   * **mask_ids** [the specification whether a specific token should be masked out (we mask out '[PAD]' tokens)]\n",
    "   * **sequence_ids** [used to denote whether a token is part of the first, second, or other segment in each input example. For us, this will always be '0'.]\n",
    "* prepare the labels  \n",
    "\n",
    "Some complications can include:\n",
    "- some words may not be in vocab\n",
    "- words can get split into multiple tokens. What are the labels?\n",
    "- Sentences do not all have the same length. Padding!\n",
    "- usual formatting details, like \"10,000\" and \"\"\" for quotes in this case.\n",
    "\n",
    "**2) Analyze and prepare the data**\n",
    "* Identify balance/imbalance situation\n",
    "* Estimate baseline accuracy defined by 'always picking the most common token'\n",
    "* Split into training and test set\n",
    "\n",
    "**3) Build the model**\n",
    "* Build BERT layer\n",
    "* Add classification layer(s)\n",
    "* Define custom loss functions and metrics\n",
    "\n",
    "**4) Run a few experiments**\n",
    "* Allow for re-training of a few BERT layers\n",
    "* Investigate the confusion matrix\n",
    "* Compare results with the model without re-training BERT layers\n",
    "* Test how good the results would be if you only at 10% of the training data (~4k sentences) \n",
    "\n",
    "\n",
    "This notebook leverages BERT and T5 implementations from Hugging Face.  \n",
    "\n",
    "The BERT part of the notebook was run with **Tensorflow 2.3** leveraging one GPU with 4 GB of memory. \n",
    "\n",
    "\n",
    "\n",
    "## II. Setup & Strategy\n",
    "\n",
    "### II.1. Data<a id=\"data\" />\n",
    "\n",
    "First, obtain the dataset (\"**Annotated Corpus for Named Entity Recognition using GMB [Groningen Meaning Bank]**\", which is shared on [Kaggle](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus). The ner_dataset.csv file is the relevant file.\n",
    "\n",
    "Let us take a quick peek at the file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",.,.,O\n",
      "Sentence: 47958,They,PRP,O\n",
      ",say,VBP,O\n",
      ",not,RB,O\n",
      ",all,DT,O\n",
      ",of,IN,O\n",
      ",the,DT,O\n",
      ",rockets,NNS,O\n",
      ",exploded,VBD,O\n",
      ",upon,IN,O\n",
      ",impact,NN,O\n",
      ",.,.,O\n",
      "Sentence: 47959,Indian,JJ,B-gpe\n",
      ",forces,NNS,O\n",
      ",said,VBD,O\n",
      ",they,PRP,O\n",
      ",responded,VBD,O\n",
      ",to,TO,O\n",
      ",the,DT,O\n",
      ",attack,NN,O\n"
     ]
    }
   ],
   "source": [
    "!tail -20 'ner_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the words line-by-line, the labels (POS and NER), and the sentence boundaries. Perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Imports:  <a id=\"bert\" />\n",
    "\n",
    "We will use the cased base BERT implementation from Hugging Face (https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel(\"ERROR\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT is easily imported from **Hugging Face's transformer library**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the two components we need are the **model** and the **tokenizer**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some key parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './'  # path to ner_dataset.csv file , from \n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "\n",
    "# make sure that the paths are accessible within the notebook\n",
    "sys.path.insert(0,data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we will need to do quite a bit of pre-processing. BERT - as well as NER in general - requires us to process the text in a larger context, which suggests that we should send the data to BERT sentence-by-sentence. (An alternative would also be to just chunk up the text, irrespective of sentence boundaries.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Preprocessing <a id=\"preprocess\" />\n",
    "\n",
    "### III.1 BERT Tokenizer<a id=\"tokenizer\" />\n",
    "\n",
    "We need to define the tokenizer. BERT has its own and that is the one that should be used. As it is specific to the (pre-trained) model, we need to specify it. For obvious reasons we will use the 'cased'  model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0d991319fe4b42a12bf46cd8ee84a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with the tokenizer. You will see that the tokenizer occasionally splits one word into multiple tokens. Why is that the case? Because the approach of using word pieces reduces the vocabulary size and/or number of unknown words.\n",
    "\n",
    "Here is one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"'\", 'll', 'learn', 'to', 'swim', 'in', '123', '##42', 'years', '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('I\\'ll learn to swim in 12342 years.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the \"I'll\" phrase and the number '12342' got split. This already highlights an area one needs to address: splitting of tokens will need to be accounted for in the labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 178, 112, 1325, 3858, 1106, 11231, 1107, 13414, 23117, 1201, 119]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids([\n",
    "    '[CLS]', 'i', \"'\",'ll', 'learn','to','swim','in','123', '##42', 'years', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Faye']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([20958])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now we are ready to use it for our text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2. Extraction<a id=\"extract\"/>\n",
    "\n",
    "\n",
    "We have seen above how the data set looks. We can now turn to the pre-processing and creating the input for BERT. Specifically, we need to:\n",
    "\n",
    "1) Tokenize the sentences. Note again that one word can be split into multiple tokens, and we need to insert custom labels when that happens to make sure we don't mess up the alignment. We choose a new 'nerX' label here.\n",
    "\n",
    "2) Create BERT tokens and add [CLS], [PAD], etc.\n",
    "\n",
    "3) Convert these tokens into ids, also via the tokenizer. These qill create the sentence_ids.\n",
    "\n",
    "4) Create the mask ids. Mask out all of the padding tokens.\n",
    "\n",
    "5) Create the sequence ids. In our case, they are all '0' as we do not compare or even have multiple sentences in one example.\n",
    "\n",
    "To do this, we first define a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word, pos, ner):\n",
    "    \"\"\"\n",
    "    Convert a word into a word token and add supplied NER and POS labels. Note that the word can be  \n",
    "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n",
    "    maintain the 1:1 mappings between word tokens and labels.\n",
    "    \n",
    "    arguments: word, pos label, ner label\n",
    "    returns: dictionary with tokens and labels\n",
    "    \"\"\"\n",
    "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
    "    if word == '\"\"\"\"':\n",
    "        word = '\"'\n",
    "    elif word == '``':\n",
    "        word = '`'\n",
    "        \n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
    "    \n",
    "    addDict = dict()\n",
    "    \n",
    "    addDict['wordToken'] = tokens\n",
    "    addDict['posToken'] = [pos] + ['posX'] * (tokenLength - 1)\n",
    "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
    "    addDict['tokenLength'] = tokenLength\n",
    "    \n",
    "    \n",
    "    return addDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['protest'],\n",
       " 'posToken': ['VB'],\n",
       " 'nerToken': ['O'],\n",
       " 'tokenLength': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('protest', 'VB', 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['Iraq'],\n",
       " 'posToken': ['NNP'],\n",
       " 'nerToken': ['B-geo'],\n",
       " 'tokenLength': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('Iraq', 'NNP', 'B-geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['1000', '##0'],\n",
       " 'posToken': ['CD', 'posX'],\n",
       " 'nerToken': ['O', 'nerX'],\n",
       " 'tokenLength': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('10000', 'CD', 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to convert the text file into appropriate arrays. First, we need to define the length of each example. For this we will define the hyper-parameter max_length. All sentences longer (post-tokenization!) than this parameter will be clipped off, and all sentences that are shorter will be padded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the file line by line and construct sentences. A sentence end is marked by the word 'sentence' in the next row.\n",
    "You need to take care of that. Also, you need to cap sentence length using max_length. Sentences which are shorter than \n",
    "max_length need to be padded. Also, we choose to end all sentences with a [SEP] token, padded or not. \n",
    "\"\"\"\n",
    "\n",
    "with io.open(data_path + 'ner_dataset.csv', 'r', encoding='utf-8', errors='ignore') as train:\n",
    "    text = train.readlines()\n",
    "\n",
    "\n",
    "# lists for sentences, tokens, labels, etc.  \n",
    "sentenceList = []\n",
    "sentenceTokenList = []\n",
    "posTokenList = []\n",
    "nerTokenList = []\n",
    "sentLengthList = []\n",
    "\n",
    "# lists for BERT input\n",
    "bertSentenceIDs = []\n",
    "bertMasks = []\n",
    "bertSequenceIDs = []\n",
    "\n",
    "sentence = ''\n",
    "\n",
    "# always start with [CLS] tokens\n",
    "sentenceTokens = ['[CLS]']\n",
    "posTokens = ['[posCLS]']\n",
    "nerTokens = ['[nerCLS]']\n",
    "\n",
    "for line in text:\n",
    "    \n",
    "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
    "\n",
    "    sent, word, pos, ner = cleanLine.split(',')\n",
    "    \n",
    "    ner = ner[:-1]   # remove DOS token\n",
    "    \n",
    "    # if new sentence starts\n",
    "    if (sent[:8] == 'Sentence'):            \n",
    "            \n",
    "        sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "        sentLengthList.append(sentenceLength)\n",
    "        \n",
    "                    \n",
    "        # Create space for at least a final '[SEP]' token\n",
    "        if sentenceLength >= max_length - 1: \n",
    "            sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "            posTokens = posTokens[:max_length - 2]\n",
    "            nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "        # add a ['SEP'] token and padding\n",
    "        \n",
    "        sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "        \n",
    "        posTokens += ['[posSEP]'] + ['[posPAD]'] * (max_length - 1 - len(posTokens) )\n",
    "        nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "            \n",
    "        sentenceList.append(sentence)\n",
    "\n",
    "        sentenceTokenList.append(sentenceTokens)\n",
    "\n",
    "        bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "        bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "        bertSequenceIDs.append([0] * (max_length))\n",
    "                             \n",
    "        posTokenList.append(posTokens)\n",
    "        nerTokenList.append(nerTokens)\n",
    "        \n",
    "        sentence = ''\n",
    "        sentenceTokens = ['[CLS]']\n",
    "        posTokens = ['[posCLS]']\n",
    "        nerTokens = ['[nerCLS]']\n",
    "        \n",
    "        sentence += ' ' + word\n",
    "\n",
    "    addDict = addWord(word, pos, ner)\n",
    "\n",
    "    sentenceTokens += addDict['wordToken']\n",
    "    posTokens += addDict['posToken']\n",
    "    nerTokens += addDict['nerToken']\n",
    "\n",
    "# The first two list elements need to be removed. 1st line in file is a-typical, and 2nd line does not end a sentence   \n",
    "sentLengthList = sentLengthList[2:]\n",
    "sentenceTokenList = sentenceTokenList[2:]\n",
    "bertSentenceIDs = bertSentenceIDs[2:]\n",
    "bertMasks = bertMasks[2:]\n",
    "bertSequenceIDs = bertSequenceIDs[2:]\n",
    "posTokenList = posTokenList[2:]\n",
    "nerTokenList = nerTokenList[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'They', 'marched', 'from', 'the', 'Houses', 'of', 'Parliament', 'to', 'a', 'rally', 'in', 'Hyde', 'Park', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[nerCLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'I-geo', 'O', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
     ]
    }
   ],
   "source": [
    "print(nerTokenList[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertMasks[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks right. Everything past the '[SEP]' token, i.e., the '[nerSEP]' label, is masked out. Also the sequence_ids are correct: there is only one sentence, so all ids should have the same value of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSequenceIDs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. \n",
    "\n",
    "\n",
    "### III.3. Initial Data Analysis<a id=\"analysis\" />\n",
    "\n",
    "It is important to understand the dataset prior to doing any modeling or training. First, what are the length of the original sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0000e+00, 2.0000e+00, 3.0000e+00, 1.9000e+01, 1.0600e+02,\n",
       "        1.8400e+02, 3.0800e+02, 4.3000e+02, 5.1900e+02, 6.6700e+02,\n",
       "        8.2800e+02, 9.4000e+02, 1.0040e+03, 1.1560e+03, 1.2590e+03,\n",
       "        1.3620e+03, 1.4480e+03, 1.5610e+03, 1.5710e+03, 1.7080e+03,\n",
       "        1.7600e+03, 1.8350e+03, 1.9350e+03, 1.9450e+03, 1.9120e+03,\n",
       "        1.8550e+03, 1.9040e+03, 1.9736e+04]),\n",
       " array([ 2.        ,  2.96428571,  3.92857143,  4.89285714,  5.85714286,\n",
       "         6.82142857,  7.78571429,  8.75      ,  9.71428571, 10.67857143,\n",
       "        11.64285714, 12.60714286, 13.57142857, 14.53571429, 15.5       ,\n",
       "        16.46428571, 17.42857143, 18.39285714, 19.35714286, 20.32142857,\n",
       "        21.28571429, 22.25      , 23.21428571, 24.17857143, 25.14285714,\n",
       "        26.10714286, 27.07142857, 28.03571429, 29.        ]),\n",
       " <BarContainer object of 28 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths= [l for l in sentLengthList]\n",
    "\n",
    "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An average sentence length of ~25 (incl. extra tokens!) is roughly expected. It turns out that on these types of corpora an average sentence length of ~20 tends to be seen. The big spike on the right obviously corresponds to all sentences that we had to truncate. \n",
    "\n",
    "Next, we analyze the distribution of ner labels. First, we assign numbers to the labels and look at the overall distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bertSentenceIDs)\n",
    "\n",
    "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
    "nerClasses.columns = ['tag']\n",
    "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
    "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
    "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
    "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'cat'}>]], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nerClasses[['cat']].hist(bins=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a lot of tables with value 16+... Let's see which labels these label numbers corresponds to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-art</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-art</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-art</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-art</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-art</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>nerX</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>nerX</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>nerX</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>nerX</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>nerX</td>\n",
       "      <td>20</td>\n",
       "      <td>166746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>441 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag  cat  occurences\n",
       "0    B-art    0         345\n",
       "1    B-art    1           0\n",
       "2    B-art    2           0\n",
       "3    B-art    3           0\n",
       "4    B-art    4           0\n",
       "..     ...  ...         ...\n",
       "436   nerX   16           0\n",
       "437   nerX   17           0\n",
       "438   nerX   18           0\n",
       "439   nerX   19           0\n",
       "440   nerX   20      166746\n",
       "\n",
       "[441 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n",
    "                   .rename(columns={'sym':'occurences'}))\n",
    "\n",
    "numNerClasses = nerDistribution.tag.nunique()\n",
    "\n",
    "nerDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. 16 corresponds to 'O', and all 'extension' labels (i.e., those that were not part of the original data) occur at 17+. \n",
    "\n",
    "'O' is the most common token - by far.\n",
    "\n",
    "### III.4. Baseline: Always picking 'Other'<a id=\"baseline\" />\n",
    "\n",
    "Let's see what a baseline would give for the actual text tokens, if I ALWAYS chose the most common token 'O':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8432003701378102"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_occurences = int(nerDistribution.loc[nerDistribution.tag == 'O','occurences']\\\n",
    "                                .reset_index().drop(['index'], axis=1).loc[16])   # Some gymnasics to get the count..\n",
    "All_occurences = nerDistribution[nerDistribution.cat < 17]['occurences'].sum()\n",
    "\n",
    "O_occurences/All_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **84.3%** is the baseline to beat for our first metric! Can we do that? We'll see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5. Train/Test Split and Final Data Preparation<a id=\"split\" />\n",
    "\n",
    "In the last step we need to prepare both labels and input for the model, including the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split - in a pretty manual way - the examples into a train and test set. We create a random binary value for each sentence that we use to split train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bert_inputs[0])\n",
    "np.random.seed(0)\n",
    "training_examples = np.random.binomial(1, 0.7, numSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSentence_ids = []\n",
    "trainMasks = []\n",
    "trainSequence_ids = []\n",
    "\n",
    "testSentence_ids = []\n",
    "testMasks = []\n",
    "testSequence_ids = []\n",
    "\n",
    "nerLabels_train =[]\n",
    "nerLabels_test = []\n",
    "\n",
    "\n",
    "for example in range(numSentences):\n",
    "    if training_examples[example] == 1:\n",
    "        trainSentence_ids.append(bert_inputs[0][example])\n",
    "        trainMasks.append(bert_inputs[1][example])\n",
    "        trainSequence_ids.append(bert_inputs[2][example])\n",
    "        nerLabels_train.append(nerLabels[example])\n",
    "    else:\n",
    "        testSentence_ids.append(bert_inputs[0][example])\n",
    "        testMasks.append(bert_inputs[1][example])\n",
    "        testSequence_ids.append(bert_inputs[2][example])\n",
    "        nerLabels_test.append(nerLabels[example])\n",
    "        \n",
    "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
    "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
    "\n",
    "nerLabels_train = np.array(nerLabels_train)\n",
    "nerLabels_test = np.array(nerLabels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101, 26159,  1104,  8568,  4487,  5067,  1138,  9639,  1194,\n",
       "        1498,  1106,  5641,  1103,  1594,  1107,  5008,  1105,  4555,\n",
       "        1103, 10602,  1104,  1418,  2830,  1121,  1115,  1583,   119,\n",
       "         102,     0,     0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 16, 16, 16, 20, 20, 16, 16, 16,  2, 16, 16, 16, 16, 16,  2, 16,\n",
       "       16, 16, 16, 16,  3, 16, 16, 16, 16, 16, 19, 18, 18], dtype=int8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerLabels_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Thousands', 'of', 'demons', '##tra', '##tors', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.', '[SEP]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also get a few train/test positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_examples[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, we prepare the actual train and test input and label data. For convenience (quick functionality test on small data set), we introduce parameters k_start & k_end to just use a slide of the full dataset. (Setting k_end to -1 corresponds to using the whole set (as we will do in the following). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
    "\n",
    "k_start = 0\n",
    "k_end = -1\n",
    "\n",
    "if k_end == -1:\n",
    "    k_end_train = X_train[0].shape[0]\n",
    "    k_end_test = X_test[0].shape[0]\n",
    "else:\n",
    "    k_end_train = k_end_test = k_end\n",
    "    \n",
    "\n",
    "\n",
    "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
    "                       X_train[2][k_start:k_end_train]]\n",
    "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
    "                      X_test[2][k_start:k_end_test]]\n",
    "\n",
    "\n",
    "labels_train_k = nerLabels_train[k_start:k_end_train]\n",
    "labels_test_k = nerLabels_test[k_start:k_end_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = [bert_inputs_train_k, labels_train_k]\n",
    "test_all = [bert_inputs_test_k, labels_test_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"./bert_train_data.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(train_all, output_file)\n",
    "    \n",
    "with open(r\"./bert_test_data.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(test_all, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"./bert_train_data.pickle\", \"rb\") as input_file:\n",
    "    bert_inputs_train_k, labels_train_k = train_all = pickle.load(input_file)\n",
    "    \n",
    "with open(r\"./bert_test_data.pickle\", \"rb\") as input_file:\n",
    "    bert_inputs_test_k, labels_test_k = test_all = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. We are all set to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. The Model<a id=\"model\"/>\n",
    "\n",
    "### IV.1. Custom Loss & Accuracy<a id=\"custom\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a **custom loss function** because we only want to optimize for the labels that we actually had in the text, not the extra ones like '[nerPAD]', etc. Our cost function is therefore derived from sparse_categorical_crossentropy, but we choose to modify the function a bit:  we want to mask out all tokens that have a token id larger or equal of 17, corresponding to the extra tokens:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length + 1) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns:  cost\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
    "    \n",
    "    mask = (y_label < 17)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
    "\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
    "    \n",
    "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
    "    \n",
    "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
    "    \n",
    "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it work as advertised? Let's create a toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[17],[0]])\n",
    "\n",
    "y_pred = tf.constant([\n",
    "    [0.6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,.4,0,0,0],\n",
    "    [0.6,0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5108275, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.constant([[17],[0]])\n",
    "\n",
    "y_pred = tf.constant([\n",
    "    [0.0,0,0,0.6,0,0,0,0,0,0,0,0,0,0,0,0,0,.4,0,0,0],\n",
    "    [0.6,0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "])\n",
    "\n",
    "\n",
    "# Nice to have eager execution now...\n",
    "\n",
    "print(custom_loss(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the manual calculation of $-\\log((y^1_{pred})_0)$ (remember that $y^0$ is masked out because the true label is 17) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5108256237659907"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is correct! The position where the true label is 17 is ignored because of the mask!\n",
    "\n",
    "In a similar vein, we define and test a **custom accuracy** calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction filtering out also the newly inserted labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 17)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also define another accuracy calculation that only looks at the non-Other labels: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_non_other_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 16)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.constant([[17],[0]])\n",
    "\n",
    "y_pred = tf.constant([\n",
    "    [0.6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,.4,0,0,0],\n",
    "    [0.6,0.4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "])\n",
    "\n",
    "\n",
    "print(custom_acc_orig_tokens(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again... correct! The false value for the '17' example is not considered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, define an Adam optimizer with new learning rate and beta parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_customized = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the summary statistics for TensorBoard. And then we can construct the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.2 Model Construction<a id=\"ner_model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to build the model! Let's be pretty simple. No drop-out etc for now. But we re-train three BERT layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_model(max_input_length, train_layers, optimizer):\n",
    "    \"\"\"\n",
    "    Implementation of NER model\n",
    "    \n",
    "    variables:\n",
    "        max_input_length: number of tokens (max_length + 1)\n",
    "        train_layers: number of layers to be retrained\n",
    "        optimizer: optimizer to be used\n",
    "    \n",
    "    returns: model\n",
    "    \"\"\"\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n",
    "    \n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n",
    "    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n",
    "    \n",
    "    bert_layer = TFBertModel.from_pretrained('bert-base-cased')\n",
    "    \n",
    "    # Freeze layers, i.e. only train number of layers specified, starting from the top\n",
    "    \n",
    "    if not train_layers == -1:\n",
    "        \n",
    "        retrain_layers = []\n",
    "    \n",
    "        for retrain_layer_number in range(train_layers):\n",
    "\n",
    "            layer_code = '_' + str(11 - retrain_layer_number)\n",
    "            retrain_layers.append(layer_code)\n",
    "\n",
    "        for w in bert_layer.weights:\n",
    "            if not any([x in w.name for x in retrain_layers]):\n",
    "                w._trainable = False\n",
    "\n",
    "        # End of freezing section\n",
    "    \n",
    "    bert_sequence = bert_layer(bert_inputs)[0]\n",
    "    \n",
    "    print('Let us check the shape of the BERT layer output:', bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(21, activation='softmax', name='ner')(dense)\n",
    "     \n",
    "    print('pred: ', pred)\n",
    "    \n",
    "    ## Prepare for multipe loss functions, although not used here\n",
    "    \n",
    "    losses = {\n",
    "        \"ner\": custom_loss,\n",
    "        }\n",
    "    lossWeights = {\"ner\": 1.0\n",
    "                  }\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "\n",
    "    model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens, \n",
    "                                                          custom_acc_orig_non_other_tokens])\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## V. Model Runs/Experiments<a id=\"runs\"/>\n",
    "\n",
    "### V.1. With BERT-Layer Re-Training<a id=\"retrain\"/>\n",
    "\n",
    "It is time to run the first test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101, 26159,  1104,  8568,  4487,  5067,  1138,  9639,  1194,\n",
       "        1498,  1106,  5641,  1103,  1594,  1107,  5008,  1105,  4555,\n",
       "        1103, 10602,  1104,  1418,  2830,  1121,  1115,  1583,   119,\n",
       "         102,     0,     0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs_train_k[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us choose to retrain the last six layers of BERT and then train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1476a0d83df43e7a12524985a174c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/527M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 30, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
      "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 30, 21), dtype=tf.float32, name=None), name='ner/truediv:0', description=\"created by layer 'ner'\")\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30, 256)      196864      tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 30, 256)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, 30, 21)       5397        dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 108,512,533\n",
      "Trainable params: 108,512,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "2106/2106 [==============================] - 195s 88ms/step - loss: 0.1869 - custom_acc_orig_tokens: 0.9484 - custom_acc_orig_non_other_tokens: 0.7567 - val_loss: 0.1069 - val_custom_acc_orig_tokens: 0.9679 - val_custom_acc_orig_non_other_tokens: 0.8367\n",
      "Epoch 2/5\n",
      "2106/2106 [==============================] - 185s 88ms/step - loss: 0.1025 - custom_acc_orig_tokens: 0.9690 - custom_acc_orig_non_other_tokens: 0.8352 - val_loss: 0.1034 - val_custom_acc_orig_tokens: 0.9688 - val_custom_acc_orig_non_other_tokens: 0.8418\n",
      "Epoch 3/5\n",
      "2106/2106 [==============================] - 184s 87ms/step - loss: 0.0970 - custom_acc_orig_tokens: 0.9702 - custom_acc_orig_non_other_tokens: 0.8398 - val_loss: 0.1018 - val_custom_acc_orig_tokens: 0.9692 - val_custom_acc_orig_non_other_tokens: 0.8387\n",
      "Epoch 4/5\n",
      "2106/2106 [==============================] - 185s 88ms/step - loss: 0.0929 - custom_acc_orig_tokens: 0.9714 - custom_acc_orig_non_other_tokens: 0.8460 - val_loss: 0.1007 - val_custom_acc_orig_tokens: 0.9696 - val_custom_acc_orig_non_other_tokens: 0.8418\n",
      "Epoch 5/5\n",
      "2106/2106 [==============================] - 185s 88ms/step - loss: 0.0927 - custom_acc_orig_tokens: 0.9715 - custom_acc_orig_non_other_tokens: 0.8484 - val_loss: 0.1003 - val_custom_acc_orig_tokens: 0.9697 - val_custom_acc_orig_non_other_tokens: 0.8440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3f43085b0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# retrain all layers\n",
    "model = ner_model(max_length + 1, train_layers=-1, optimizer = adam_customized)\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_k, \n",
    "    {\"ner\": labels_train_k },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k }),\n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8866547245089735090\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6551896064\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14855078815134669919\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070, pci bus id: 0000:0b:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**97.0% test accuracy for all original tokens and 84.4% for all original 'non-Other' tokens.... Not bad!!** And some tweaking and tuning should probably increase the values a bit more.\n",
    "\n",
    "Note that we used here the **Adam optimizer with custom values. Did that matter?** Why don't you try it...\n",
    "\n",
    "### V.2. Predictions & Confusion Matrix<a id=\"confusion\" />\n",
    "\n",
    "\n",
    "Let us look and see how well the model performs. We use the test here. (It probably would be better to split the data into train/validation/test, we are somewhat casual here).\n",
    "\n",
    "First, get all of the predictions for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs_infer = [X_test[0], X_test[1], X_test[2]]\n",
    "\n",
    "result = model.predict(\n",
    "    bert_inputs_infer, \n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14268, 30, 21)\n"
     ]
    }
   ],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the correct shape: # test sentences x sentence length x # classes. \n",
    "Let's get the prediction argmax for a random test sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 16 16 16 16 16 16 16 16 16 16 16 16 16 16 16  2 16 16 16  6 14 14 14\n",
      " 14 16 16 16 16 16]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(result, axis=2)[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What were the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 16 20 20 16 20 16 16 16 16 16 16 16 16 16 16  2 16 20 16  6 14 20 14\n",
      " 14 16 19 18 18 18]\n"
     ]
    }
   ],
   "source": [
    "print(nerLabels_test[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wrong? Correct!** Or.. is it?  \n",
    "\n",
    "**Question: Why are we not bothered by the first and the last 'mistakes', i.e., not identifying 20, 17, 19, 18, etc.?**\n",
    "\n",
    "Let us now get the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_flat = [pred for preds in np.argmax(result, axis=2) for pred in preds]\n",
    "labels_flat = [label for labels in nerLabels_test for label in labels]\n",
    "\n",
    "clean_preds = []\n",
    "clean_labels = []\n",
    "\n",
    "for pred, label in zip(predictions_flat, labels_flat):\n",
    "    if label < 17:\n",
    "        clean_preds.append(pred)\n",
    "        clean_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(\n",
    "    clean_labels,\n",
    "    clean_preds,\n",
    "    num_classes=None,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=None,\n",
    "    weights=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably a little big and unbalanced to display. Let us focus on the rows/columns with the common labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,     28,  10265,   4197,      0,   4792,   4841,   5069,\n",
       "            1,      7,   1819,     25,      0,   4180,   5212,   1409,\n",
       "       227865])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(cm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8794     63    355    137     14     36     56    222]\n",
      " [   205   3995     35      2      0      3      0      8]\n",
      " [   662     49   3770    277     14    107    111    380]\n",
      " [   156      1    152   4068      1     40    189    150]\n",
      " [    78      2     14      3   4617      8      2    375]\n",
      " [    75     10     73     67      0   3321    264    321]\n",
      " [     1      2      6    129      0    139   4379     40]\n",
      " [   187     59    305    144    303    270    132 225960]]\n"
     ]
    }
   ],
   "source": [
    "cm_most = np.array(cm)[[2,3,5,6,7,13,14,16],:] [:, [2,3,5,6,7,13,14,16]]\n",
    "\n",
    "print(cm_most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff1b38c78e0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cm_most[:-1,:-1], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.3 Without BERT-Layer Retraining (\"Did fine-tuning of BERT layers help?\")\n",
    "\n",
    "We will re-run the model, but without re-training of the top BERT layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 30, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
      "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 30, 21), dtype=tf.float32, name=None), name='ner/truediv:0', description=\"created by layer 'ner'\")\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30, 256)      196864      tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 30, 256)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, 30, 21)       5397        dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 108,512,533\n",
      "Trainable params: 108,512,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/8\n",
      "1053/1053 [==============================] - 65s 60ms/step - loss: 0.2916 - custom_acc_orig_tokens: 0.9256 - custom_acc_orig_non_other_tokens: 0.6118 - val_loss: 0.1357 - val_custom_acc_orig_tokens: 0.9599 - val_custom_acc_orig_non_other_tokens: 0.7854\n",
      "Epoch 2/8\n",
      "1053/1053 [==============================] - 62s 58ms/step - loss: 0.1398 - custom_acc_orig_tokens: 0.9584 - custom_acc_orig_non_other_tokens: 0.7785 - val_loss: 0.1244 - val_custom_acc_orig_tokens: 0.9625 - val_custom_acc_orig_non_other_tokens: 0.8059\n",
      "Epoch 3/8\n",
      "1053/1053 [==============================] - 62s 59ms/step - loss: 0.1280 - custom_acc_orig_tokens: 0.9610 - custom_acc_orig_non_other_tokens: 0.7922 - val_loss: 0.1205 - val_custom_acc_orig_tokens: 0.9636 - val_custom_acc_orig_non_other_tokens: 0.8092\n",
      "Epoch 4/8\n",
      "1053/1053 [==============================] - 62s 59ms/step - loss: 0.1195 - custom_acc_orig_tokens: 0.9636 - custom_acc_orig_non_other_tokens: 0.8050 - val_loss: 0.1171 - val_custom_acc_orig_tokens: 0.9644 - val_custom_acc_orig_non_other_tokens: 0.8170\n",
      "Epoch 5/8\n",
      "1053/1053 [==============================] - 62s 59ms/step - loss: 0.1166 - custom_acc_orig_tokens: 0.9636 - custom_acc_orig_non_other_tokens: 0.8055 - val_loss: 0.1149 - val_custom_acc_orig_tokens: 0.9648 - val_custom_acc_orig_non_other_tokens: 0.8114\n",
      "Epoch 6/8\n",
      "1053/1053 [==============================] - 62s 59ms/step - loss: 0.1096 - custom_acc_orig_tokens: 0.9655 - custom_acc_orig_non_other_tokens: 0.8151 - val_loss: 0.1157 - val_custom_acc_orig_tokens: 0.9645 - val_custom_acc_orig_non_other_tokens: 0.8144\n",
      "Epoch 7/8\n",
      "1053/1053 [==============================] - 62s 59ms/step - loss: 0.1074 - custom_acc_orig_tokens: 0.9661 - custom_acc_orig_non_other_tokens: 0.8184 - val_loss: 0.1132 - val_custom_acc_orig_tokens: 0.9656 - val_custom_acc_orig_non_other_tokens: 0.8174\n",
      "Epoch 8/8\n",
      "1053/1053 [==============================] - 62s 59ms/step - loss: 0.1048 - custom_acc_orig_tokens: 0.9665 - custom_acc_orig_non_other_tokens: 0.8210 - val_loss: 0.1134 - val_custom_acc_orig_tokens: 0.9651 - val_custom_acc_orig_non_other_tokens: 0.8188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff1b2d5e9d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n",
    "\n",
    "# Instantiate variables\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_k, \n",
    "    {\"ner\": labels_train_k },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
    "    epochs=8,\n",
    "    batch_size=32\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Somewhat close, but not quite as good.** - While one has to be careful given the different optimizer configurations and number of epochs, it looks as if not re-training BERT - in this case - increased the loss and reduced the accuracy a bit. Let's call this **~96.6%/81.8% accuracy** compared to 97.0%/84.4%. \n",
    "\n",
    "The relative benefit of fine-tuning BERT layers will depend on the problem.\n",
    "\n",
    "**Side Notes:** \n",
    " * Deeper re-training needs more compute resources\n",
    " * Deeper re-training sometimes requires a tuned optimizer\n",
    " * Regularization is definitely important..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.4. A 90%-Reduced Training Set<a id=\"tiny\"/>\n",
    "\n",
    "\n",
    "The claim is that BERT is also very useful if one doesn't have much data. So let us see what happens if we cut the training data down to 10%. That leaves us with only ~3400 training examples. Not much..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 33690, 30)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrainSentences = 3370\n",
    "\n",
    "bert_inputs_train_tiny = [bert_inputs_train_k[0][:numTrainSentences,:], \\\n",
    "                          bert_inputs_train_k[1][:numTrainSentences,:], \\\n",
    "                          bert_inputs_train_k[2][:numTrainSentences,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train_tiny = labels_train_k[:numTrainSentences,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first train without BERT-layer fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 30, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
      "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 30, 21), dtype=tf.float32, name=None), name='ner/truediv:0', description=\"created by layer 'ner'\")\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30, 256)      196864      tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 30, 256)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, 30, 21)       5397        dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 108,512,533\n",
      "Trainable params: 108,512,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "211/211 [==============================] - 8s 25ms/step - loss: 0.6390 - custom_acc_orig_tokens: 0.8484 - custom_acc_orig_non_other_tokens: 0.3291\n",
      "Epoch 2/5\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1830 - custom_acc_orig_tokens: 0.9486 - custom_acc_orig_non_other_tokens: 0.7157\n",
      "Epoch 3/5\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1567 - custom_acc_orig_tokens: 0.9532 - custom_acc_orig_non_other_tokens: 0.7496\n",
      "Epoch 4/5\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1378 - custom_acc_orig_tokens: 0.9578 - custom_acc_orig_non_other_tokens: 0.7745\n",
      "Epoch 5/5\n",
      "211/211 [==============================] - 5s 24ms/step - loss: 0.1293 - custom_acc_orig_tokens: 0.9594 - custom_acc_orig_non_other_tokens: 0.7832\n",
      "211/211 [==============================] - 25s 121ms/step - loss: 0.1199 - custom_acc_orig_tokens: 0.9625 - custom_acc_orig_non_other_tokens: 0.8008 - val_loss: 0.1635 - val_custom_acc_orig_tokens: 0.9535 - val_custom_acc_orig_non_other_tokens: 0.7716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3881e5610>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# retrain all layers\n",
    "model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_tiny, \n",
    "    {\"ner\": labels_train_tiny },\n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")\n",
    "model.fit(\n",
    "    bert_inputs_train_tiny, \n",
    "    {\"ner\": labels_train_tiny },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
    "    epochs=1,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad, one would think! **~95.3%/75.0%** on the test set, compared to ~96.6%/81.8% accuracy on the full training set (w/o BERT-layer re-training) with 1/10th of the data. So BERT embeddings are serving quite well for a smaller data set. \n",
    "\n",
    "At last, let us also compare this to the case where we retrain all BERT layers. This will shed light on the question whether retraining pays off relatively more when data is scarce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 30, 768), dtype=tf.float32, name=None), name='tf_bert_model_1/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model_1'\")\n",
      "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 30, 21), dtype=tf.float32, name=None), name='ner/truediv:0', description=\"created by layer 'ner'\")\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_1 (TFBertModel)   TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30, 256)      196864      tf_bert_model_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 30, 256)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, 30, 21)       5397        dropout_75[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 108,512,533\n",
      "Trainable params: 108,512,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "211/211 [==============================] - 24s 78ms/step - loss: 1.5574 - custom_acc_orig_tokens: 0.6780 - custom_acc_orig_non_other_tokens: 0.0039\n",
      "Epoch 2/5\n",
      "211/211 [==============================] - 16s 78ms/step - loss: 0.6077 - custom_acc_orig_tokens: 0.8465 - custom_acc_orig_non_other_tokens: 0.0271\n",
      "Epoch 3/5\n",
      "211/211 [==============================] - 16s 78ms/step - loss: 0.4619 - custom_acc_orig_tokens: 0.8707 - custom_acc_orig_non_other_tokens: 0.2094\n",
      "Epoch 4/5\n",
      "211/211 [==============================] - 16s 78ms/step - loss: 0.3676 - custom_acc_orig_tokens: 0.8969 - custom_acc_orig_non_other_tokens: 0.3584\n",
      "Epoch 5/5\n",
      "211/211 [==============================] - 16s 78ms/step - loss: 0.3216 - custom_acc_orig_tokens: 0.9137 - custom_acc_orig_non_other_tokens: 0.4778\n",
      "211/211 [==============================] - 37s 176ms/step - loss: 0.2816 - custom_acc_orig_tokens: 0.9247 - custom_acc_orig_non_other_tokens: 0.5538 - val_loss: 0.2598 - val_custom_acc_orig_tokens: 0.9324 - val_custom_acc_orig_non_other_tokens: 0.6122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff1996a01c0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain all layers\n",
    "model = ner_model(max_length + 1,train_layers=-1,optimizer=adam_customized)\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_tiny, \n",
    "    {\"ner\": labels_train_tiny },\n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_tiny, \n",
    "    {\"ner\": labels_train_tiny },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
    "    epochs=1,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**96.2%/80.8%** on the reduced set, compared to 97.0%/84.4% test accuracy for all original tokens and for the full dataset (both with layer re-training). That is quite good - only a loss of about 0.9%-points/4.3%-points.\n",
    "\n",
    "Compare that also to the results without layer retraining: ~95.5%/75.9% for the 1/10 data set vs ~96.6%/81.8%  for the full training set, corresponding to a 1.1%-points/5.9%-point reduction.\n",
    "\n",
    "It appears that transfer-learning for small data sets may really benefit from layer re-training. Here is the summary table:\n",
    "\n",
    "\n",
    "|Dataset         | Retrain Layers?           | Base Token Accuracy   | Base Token Accuracy w/o 'Other'   | Notes  |\n",
    "| ------------- |:-------------:| :-------------:| :-------------:|-------------:|\n",
    "| **Full**       | Yes (all) | **97.0%** | **84.4%** |custom Adam, 5 epochs|\n",
    "| **Full**       | No      |   **96.6%** | **81.8%** |default Adam, 8 epochs|\n",
    "| **1/10**  |  Yes (all)      |   **96.1%** | **80.1%** |custom Adam, 6 epochs|\n",
    "| **1/10**  | No     |    **95.5%** | **75.9%**|default Adam, 6 epochs|\n",
    "\n",
    "\n",
    "**Disclaimers/Cautions:**\n",
    "\n",
    "* The models were generally not optimized and/or run for the optimal duration. Numbers of epochs are not consistent and were selected based on 'good-enough for now'-strategy.  Quite possibly some models would benefit from more epochs (and hyper-parameter tuning). \n",
    "\n",
    "* The optimizers (default 'Adam' vs the one with customized values) were varied across model runs, which has a significant impact and results are not directly comparable. (Note: it appears that for the reduced set, the model without layer re-training does not train well on the custom Adam-optimizer, while the one where we re-train all layers does not train with the default values.)\n",
    "\n",
    "Having said this, I do not believe that the findings above would be massively different with a more stringent setup. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Summary<a id=\"summary\" />\n",
    "\n",
    "This finishes this cursory analysis of \"BERT for NER\". We pre-formatted our dataset, took care of tokenization and new inserted tokens (and labels!), defined a baseline model, and then - it would have been embarassing if we had failed - soundly beat the baseline with our Keras-based BERT+classification model. We saw that retraining of some BERT layers appeared to work well.  \n",
    "We also saw that even a small training set of about 3400 sentences did quite well using this architecture.\n",
    "\n",
    "All in all, we hope that this notebook was useful and despite its length reasonably readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: T5<a id=\"T5\" />\n",
    "\n",
    "\n",
    "Let us now lay the foundations for another useful model: **T5**. \n",
    "\n",
    "T5 is a pre-trained transformer-based text-to-text model introduced by C. Raffel et al in  [\"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"](https://arxiv.org/pdf/1910.10683.pdf) , that is also available from Huggingface.  The idea is to view/rephrase tasks as 'text-to-text' problems:   \n",
    "\n",
    "<img src=\"t5.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<center>Image Source: \"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\"</center>\n",
    "\n",
    "T5 has performed very well on a variety of tasks.\n",
    "\n",
    "In this spirit, let us approach the NER classification discussed above in a completely different may: **as a translation problem**. This may certainly lead to less good results than the BERT model, as phrasing it as a translation problem is not very natural. But it is instructive nevertheless.\n",
    "\n",
    "(**Note:** this is pretty cutting-edge as there is very little information available on fine-tuning of T5 with TensorFlow/Keras. So this notebook should be viewed as work in progress, and mistakes may be present.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "from csv import reader\n",
    "\n",
    "from transformers import TFT5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5 is available in various sizes. Here, we use the small size with about 60m parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model = 't5-small'\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is for us to rephrase NER extraction as a translation problem.\n",
    "\n",
    "So we want to frame a text-to-text task that performs the following 'translation':\n",
    "\n",
    "$$ {\\rm 'London \\ is \\ a \\ great \\ town'} \\ \\rightarrow  {\\rm 'B-loc \\ other \\ other \\ other \\ other'}$$ \n",
    "\n",
    "While it is unusual to view this as a translation problem, it is certainly valid.\n",
    "\n",
    "There are many ways to set up the data and labels. One way is to convert the NER symbols in ways that better map to language: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-art ['▁begin', '▁cultural'] [1731, 2779]\n",
      "B-eve ['▁begin', '▁event'] [1731, 605]\n",
      "B-geo ['▁begin', '▁location'] [1731, 1128]\n",
      "B-gpe ['▁begin', '▁political'] [1731, 1827]\n",
      "B-nat ['▁begin', '▁natural'] [1731, 793]\n",
      "B-org ['▁begin', '▁organization'] [1731, 1470]\n",
      "B-per ['▁begin', '▁person'] [1731, 568]\n",
      "B-tim ['▁begin', '▁time'] [1731, 97]\n",
      "I-art ['▁continue', '▁cultural'] [916, 2779]\n",
      "I-eve ['▁continue', '▁event'] [916, 605]\n",
      "I-geo ['▁continue', '▁location'] [916, 1128]\n",
      "I-gpe ['▁continue', '▁political'] [916, 1827]\n",
      "I-nat ['▁continue', '▁natural'] [916, 793]\n",
      "I-org ['▁continue', '▁organization'] [916, 1470]\n",
      "I-per ['▁continue', '▁person'] [916, 568]\n",
      "I-tim ['▁continue', '▁time'] [916, 97]\n",
      "O ['▁other'] [119]\n"
     ]
    }
   ],
   "source": [
    "tag_dict = {'B-art':'begin cultural',\n",
    " 'B-eve':'begin event',\n",
    " 'B-geo':'begin location',\n",
    " 'B-gpe':'begin political',\n",
    " 'B-nat':'begin natural',\n",
    " 'B-org':'begin organization',\n",
    " 'B-per':'begin person',\n",
    " 'B-tim':'begin time',\n",
    " 'I-art':'continue cultural',\n",
    " 'I-eve':'continue event',\n",
    " 'I-geo':'continue location',\n",
    " 'I-gpe':'continue political',\n",
    " 'I-nat':'continue natural',\n",
    " 'I-org':'continue organization',\n",
    " 'I-per':'continue person',\n",
    " 'I-tim':'continue time',\n",
    " 'O':'other'}\n",
    "\n",
    "for key, tag in tag_dict.items():\n",
    "    print(key, t5_tokenizer.tokenize(tag), t5_tokenizer.encode(tag)[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify a maximum input length (we pick 40) and create the training input and labels.\n",
    "\n",
    "Note:\n",
    "\n",
    "* we prepend each sentence with a task description. We use: 'find entities:' . The padded, encoded version of this string consitutes the encoder input. (Note: encoding adds a padding token at the beginning and a <\\/s> token at the end, prior to the padding tokens.)\n",
    "\n",
    "* For the decoder input and the labels we create the suitable NER-token string (with the language-friendly terms). The input starts off with the padding token while the labels end on the sentence-end token <\\/s>  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d9a8c1e84e86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'ner_dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_path' is not defined"
     ]
    }
   ],
   "source": [
    "max_len = 40\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "input_sentences = []\n",
    "ner_translations_input = []\n",
    "ner_translations_labels = []\n",
    "\n",
    "input_sentences_t5 = []\n",
    "ner_translations_input_t5 = []\n",
    "ner_translations_labels_t5 = []\n",
    "\n",
    "# define masks for encode4r and decoder\n",
    "enc_in_masks = []\n",
    "dec_in_masks = []\n",
    "\n",
    "###\n",
    "\n",
    "train_input_sentences_t5 = []\n",
    "train_ner_translations_input_t5 = []\n",
    "train_ner_translations_labels_t5 = []\n",
    "\n",
    "train_enc_in_masks_t5 = []\n",
    "train_dec_in_masks_t5 = []\n",
    "\n",
    "###\n",
    "\n",
    "test_input_sentences_t5 = []\n",
    "test_ner_translations_input_t5 = []\n",
    "test_ner_translations_labels_t5 = []\n",
    "\n",
    "test_enc_in_masks_t5 = []\n",
    "test_dec_in_masks_t5 = []\n",
    "\n",
    "###\n",
    "\n",
    "with io.open(data_path + 'ner_dataset.csv', 'r', encoding='utf-8', errors='ignore') as train:\n",
    "    text = train.readlines()\n",
    "\n",
    "current_input = 'find entities:'\n",
    "current_translation = '<pad>'\n",
    "current_labels = ''\n",
    "\n",
    "for line_num, line in enumerate(text):\n",
    "    \n",
    "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
    "\n",
    "    sent, word, pos, ner = [x.strip('\\n') for x in cleanLine.split(',')]\n",
    "    #print(word, ner)\n",
    "    word = word.replace('\"\"\"\"', '\"')\n",
    "    word = word.replace('\"\"', '\"')\n",
    "    \n",
    "    if sent.startswith('Sentence:'):\n",
    "        current_input += ' </s>'\n",
    "        current_translation += ' </s>'\n",
    "        current_labels += ' </s>'\n",
    "        \n",
    "        input_sentences.append(current_input)\n",
    "        ner_translations_input.append(current_translation)\n",
    "        ner_translations_labels.append(current_labels)\n",
    "        \n",
    "        \n",
    "        current_input_ids = t5_tokenizer.encode(current_input)\n",
    "        len_input = len(current_input_ids)     \n",
    "        current_input_ids += ([0]* max_len)\n",
    "        current_input_ids = current_input_ids[:max_len]\n",
    "        \n",
    "        enc_in_mask = ([1] * len_input + [0] * max_len)[:max_len]\n",
    "        \n",
    "        current_translation_ids = t5_tokenizer.encode(current_translation)\n",
    "    \n",
    "        dec_in_length = len(current_translation_ids)\n",
    "        current_translation_ids += ([0]* max_len)\n",
    "        current_translation_ids = current_translation_ids[:max_len]\n",
    "        \n",
    "        dec_in_mask = ([1] * dec_in_length + [0] * max_len)[:max_len]\n",
    "        \n",
    "        current_labels_ids = t5_tokenizer.encode(current_labels)\n",
    "        current_labels_ids += ([0]* max_len)\n",
    "        current_labels_ids = current_labels_ids[:max_len]\n",
    "\n",
    "        input_sentences_t5.append(current_input_ids)\n",
    "        ner_translations_input_t5.append(current_translation_ids)\n",
    "        ner_translations_labels_t5.append(current_labels_ids)\n",
    "        \n",
    "        enc_in_masks.append(enc_in_mask)\n",
    "        dec_in_masks.append(dec_in_mask)\n",
    "        \n",
    "        if  np.random.random()< 0.8: \n",
    "            \n",
    "            ## train\n",
    "        \n",
    "            train_input_sentences_t5.append(current_input_ids)\n",
    "            train_ner_translations_input_t5.append(current_translation_ids)\n",
    "            train_ner_translations_labels_t5.append(current_labels_ids)\n",
    "\n",
    "            train_enc_in_masks_t5.append(enc_in_mask)\n",
    "            train_dec_in_masks_t5.append(dec_in_mask)\n",
    "        else:\n",
    "            \n",
    "            ## test\n",
    "\n",
    "            test_input_sentences_t5.append(current_input_ids)\n",
    "            test_ner_translations_input_t5.append(current_translation_ids)\n",
    "            test_ner_translations_labels_t5.append(current_labels_ids)\n",
    "\n",
    "            test_enc_in_masks_t5.append(enc_in_mask)\n",
    "            test_dec_in_masks_t5.append(dec_in_mask)\n",
    "        \n",
    "        current_input = '<pad> ' + 'find entities: ' + word\n",
    "        current_translation = '<pad> ' + tag_dict[ner]\n",
    "        current_labels = ''  + tag_dict[ner]\n",
    "        \n",
    "    \n",
    "    elif sent == '':\n",
    "        current_input += ' ' + word\n",
    "        current_translation += ' ' + tag_dict[ner]\n",
    "        current_labels += ' ' + tag_dict[ner]\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "input_sentences = input_sentences[2:]\n",
    "ner_translations_input = ner_translations_input[2:]\n",
    "ner_translations_labels = ner_translations_labels[2:]\n",
    "\n",
    "input_sentences_t5 = np.array(input_sentences_t5[2:])\n",
    "ner_translations_input_t5 = np.array(ner_translations_input_t5[2:])\n",
    "ner_translations_labels_t5 = np.array(ner_translations_labels_t5[2:])\n",
    "enc_in_masks_t5 = np.array(enc_in_masks[2:])\n",
    "dec_in_masks_t5 = np.array(dec_in_masks[2:])\n",
    "\n",
    "train_input_sentences_t5 = np.array(train_input_sentences_t5[2:])\n",
    "train_ner_translations_input_t5 = np.array(train_ner_translations_input_t5[2:])\n",
    "train_ner_translations_labels_t5 = np.array(train_ner_translations_labels_t5[2:])\n",
    "train_enc_in_masks_t5 = np.array(train_enc_in_masks_t5[2:])\n",
    "train_dec_in_masks_t5 = np.array(train_dec_in_masks_t5[2:])\n",
    "\n",
    "test_input_sentences_t5 = np.array(test_input_sentences_t5[2:])\n",
    "test_ner_translations_input_t5 = np.array(test_ner_translations_input_t5[2:])\n",
    "test_ner_translations_labels_t5 = np.array(test_ner_translations_labels_t5[2:])\n",
    "test_enc_in_masks_t5 = np.array(test_enc_in_masks_t5[2:])\n",
    "test_dec_in_masks_t5 = np.array(test_dec_in_masks_t5[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dec_in_masks_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are examples of input sentence, decoder input string, and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> find entities: They marched from the Houses of Parliament to a rally in Hyde Park . </s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> other other other other other other other other other other other begin location continue location other </s>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_translations_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'other other other other other other other other other other other begin location continue location other </s>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_translations_labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check the corresponding encoder and decoder input masks that are supposed to mask outpad tokens: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_in_masks_t5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(enc_in_masks_t5[1]) == len(t5_tokenizer.encode(input_sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_in_masks_t5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(dec_in_masks_t5[1]) == len(t5_tokenizer.encode(ner_translations_input[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Masks haver the right lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like before in the BERT architecture we define custom accuracies and custom loss functions:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_custom_acc_orig_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    accuracy across all non-padding/non-eos tokens. \n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    numNerClasses = y_pred.shape[-1]\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask =  (y_label > 1)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_custom_acc_orig_tokens_no_other(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    accuracy across all non-padding/non-eos tokens except for 'other'-token.\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    numNerClasses = y_pred.shape[-1]\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask_119 =  (y_label != 119)\n",
    "    #print('mask_119', mask_119)\n",
    "    mask_0 =  (y_label > 1)\n",
    "    #print('mask_0', mask_0)\n",
    "    mask =  tf.math.logical_and(mask_119, mask_0)\n",
    "    #print('mask', mask)\n",
    "    \n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_custom_acc_orig_tokens_begin_cont(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    accuracty for 'begin'- and 'continue'-tokens\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    numNerClasses = y_pred.shape[-1]\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    mask_916 =  (y_label == 916)\n",
    "    mask_1731 =  (y_label == 1731)\n",
    "    \n",
    "    begin_cont_mask = tf.math.logical_or(mask_916, mask_1731)\n",
    "    \n",
    "    #print('mask_119', mask_119)\n",
    "    mask_0 =  (y_label > 1)\n",
    "    #print('mask_0', mask_0)\n",
    "    mask =  tf.math.logical_and(begin_cont_mask, mask_0)\n",
    "    #print('mask', mask)\n",
    "    \n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_custom_acc_orig_tokens_not_begin_cont_other(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    accuracy for the actual non-'other' tokens, excluding also 'begin'- and 'continue'-tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    numNerClasses = y_pred.shape[-1]\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    mask_916 =  (y_label != 916)\n",
    "    mask_1731 =  (y_label != 1731)\n",
    "    mask_119 =  (y_label != 119)\n",
    "    \n",
    "    not_begin_cont_other_mask = tf.math.logical_and(tf.math.logical_and(mask_916, mask_1731), mask_119)\n",
    "    \n",
    "    #print('mask_119', mask_119)\n",
    "    mask_0 =  (y_label > 1)\n",
    "    #print('mask_0', mask_0)\n",
    "    mask =  tf.math.logical_and(not_begin_cont_other_mask, mask_0)\n",
    "    #print('mask', mask)\n",
    "    \n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a few tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.constant([[[0.5,0.2,0.3, 0.0], [0.1,0.7,0.2, 0.0], [0.1,0.3,0.6, 0.0], [0.1,0.3,0.0, 0.6]]])\n",
    "y_true = tf.constant([[1], [0], [2], [3]])\n",
    "\n",
    "t5_custom_acc_orig_tokens_no_other(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, let's define a custom loss function that removes padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length + 1) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns:  cost\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    numNerClasses = y_pred.shape[-1]\n",
    "    \n",
    "    #print('numNerClasses', numNerClasses)\n",
    "    \n",
    "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
    "    \n",
    "    mask = (y_label > 1)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
    "\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
    "    \n",
    "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
    "    \n",
    "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
    "    \n",
    "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=True ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model consists of 3 inputs:\n",
    "\n",
    "* the input ids \n",
    "* the masks to mask out padding in the encoder\n",
    "* the decoder ids from the NER string\n",
    "\n",
    "We then use the **TFT5ForConditionalGeneration** model to implement our task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_keras_model():\n",
    "    \n",
    "    \n",
    "    encode_in = tf.keras.layers.Input(shape=(max_len,), dtype='int32', name=\"encode_in_ids\")\n",
    "    enc_mask_in = tf.keras.layers.Input(shape=(max_len,), dtype='int32', name=\"enc_mask_in_ids\")\n",
    "    decode_in = tf.keras.layers.Input(shape=(None,), dtype='int32', name=\"decode_in_ids\")\n",
    "    dec_mask_in = tf.keras.layers.Input(shape=(None,), dtype='int32', name=\"dec_mask_in_ids\")\n",
    "    \n",
    "    t5_layer = TFT5ForConditionalGeneration.from_pretrained(t5_model)\n",
    "    \n",
    "    t5_out = t5_layer({'input_ids': encode_in, \n",
    "                       'decoder_input_ids':decode_in, \n",
    "                       'attention_mask':enc_mask_in,\n",
    "                       'decoder_attention_mask':dec_mask_in\n",
    "                      }, \n",
    "                             return_dict=True)\n",
    "    \n",
    "    pred_logits = t5_out['logits']\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[encode_in, \n",
    "                                          enc_mask_in, \n",
    "                                          decode_in,\n",
    "                                          dec_mask_in\n",
    "                                         ], \n",
    "                                  outputs=pred_logits)\n",
    "\n",
    "    model.compile(loss=t5_custom_loss, \n",
    "                  optimizer=tf.keras.optimizers.Adam(), \n",
    "                  metrics=[\n",
    "                  #     tf.keras.metrics.Accuracy(),\n",
    "                          t5_custom_acc_orig_tokens, \n",
    "                           t5_custom_acc_orig_tokens_no_other,\n",
    "                      t5_custom_acc_orig_tokens_begin_cont,\n",
    "                      t5_custom_acc_orig_tokens_not_begin_cont_other\n",
    "                  #\n",
    "                  ]\n",
    "                 )\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8e274261a04f43bd8387efbb6e95a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d7537aba0a4d268602b9167142b53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_mask_in_ids (InputLayer)    [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_mask_in_ids (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decode_in_ids (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encode_in_ids (InputLayer)      [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_t5for_conditional_generation TFSeq2SeqLMOutput(lo 60506624    enc_mask_in_ids[0][0]            \n",
      "                                                                 dec_mask_in_ids[0][0]            \n",
      "                                                                 decode_in_ids[0][0]              \n",
      "                                                                 encode_in_ids[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 60,506,624\n",
      "Trainable params: 60,506,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del t5_ner_model\n",
    "except:\n",
    "    pass\n",
    "\n",
    "t5_ner_model = t5_keras_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we have about 60m parameters.\n",
    "\n",
    "We now use Keras to fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "2396/2396 [==============================] - 264s 106ms/step - loss: 0.3931 - t5_custom_acc_orig_tokens: 0.8780 - t5_custom_acc_orig_tokens_no_other: 0.6371 - t5_custom_acc_orig_tokens_begin_cont: 0.5057 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.7690 - val_loss: 0.1028 - val_t5_custom_acc_orig_tokens: 0.9634 - val_t5_custom_acc_orig_tokens_no_other: 0.9058 - val_t5_custom_acc_orig_tokens_begin_cont: 0.8897 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9218\n",
      "Epoch 2/6\n",
      "2396/2396 [==============================] - 252s 105ms/step - loss: 0.1143 - t5_custom_acc_orig_tokens: 0.9584 - t5_custom_acc_orig_tokens_no_other: 0.8831 - t5_custom_acc_orig_tokens_begin_cont: 0.8518 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9145 - val_loss: 0.1070 - val_t5_custom_acc_orig_tokens: 0.9596 - val_t5_custom_acc_orig_tokens_no_other: 0.8666 - val_t5_custom_acc_orig_tokens_begin_cont: 0.8105 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9228\n",
      "Epoch 3/6\n",
      "2396/2396 [==============================] - 255s 106ms/step - loss: 0.0929 - t5_custom_acc_orig_tokens: 0.9665 - t5_custom_acc_orig_tokens_no_other: 0.9031 - t5_custom_acc_orig_tokens_begin_cont: 0.8824 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9239 - val_loss: 0.0846 - val_t5_custom_acc_orig_tokens: 0.9702 - val_t5_custom_acc_orig_tokens_no_other: 0.9110 - val_t5_custom_acc_orig_tokens_begin_cont: 0.8946 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9275\n",
      "Epoch 4/6\n",
      "2396/2396 [==============================] - 256s 107ms/step - loss: 0.0795 - t5_custom_acc_orig_tokens: 0.9713 - t5_custom_acc_orig_tokens_no_other: 0.9170 - t5_custom_acc_orig_tokens_begin_cont: 0.9021 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9319 - val_loss: 0.0768 - val_t5_custom_acc_orig_tokens: 0.9740 - val_t5_custom_acc_orig_tokens_no_other: 0.9260 - val_t5_custom_acc_orig_tokens_begin_cont: 0.9207 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9314\n",
      "Epoch 5/6\n",
      "2396/2396 [==============================] - 258s 108ms/step - loss: 0.0721 - t5_custom_acc_orig_tokens: 0.9739 - t5_custom_acc_orig_tokens_no_other: 0.9243 - t5_custom_acc_orig_tokens_begin_cont: 0.9108 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9379 - val_loss: 0.0791 - val_t5_custom_acc_orig_tokens: 0.9730 - val_t5_custom_acc_orig_tokens_no_other: 0.9266 - val_t5_custom_acc_orig_tokens_begin_cont: 0.9224 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9309\n",
      "Epoch 6/6\n",
      "2396/2396 [==============================] - 259s 108ms/step - loss: 0.0657 - t5_custom_acc_orig_tokens: 0.9761 - t5_custom_acc_orig_tokens_no_other: 0.9300 - t5_custom_acc_orig_tokens_begin_cont: 0.9183 - t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9417 - val_loss: 0.0762 - val_t5_custom_acc_orig_tokens: 0.9750 - val_t5_custom_acc_orig_tokens_no_other: 0.9305 - val_t5_custom_acc_orig_tokens_begin_cont: 0.9291 - val_t5_custom_acc_orig_tokens_not_begin_cont_other: 0.9319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc5dd564580>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_off = 20000000\n",
    "\n",
    "t5_ner_model.fit([train_input_sentences_t5[:cut_off], \n",
    "                      train_enc_in_masks_t5[:cut_off], \n",
    "                      train_ner_translations_input_t5[:cut_off],\n",
    "                      train_dec_in_masks_t5[:cut_off]\n",
    "                     ],\n",
    "                   train_ner_translations_labels_t5[:cut_off],\n",
    "                 validation_data=([test_input_sentences_t5[:cut_off],\n",
    "                                   test_enc_in_masks_t5[:cut_off], \n",
    "                                   test_ner_translations_input_t5[:cut_off],\n",
    "                                   test_dec_in_masks_t5[:cut_off]],\n",
    "                                test_ner_translations_labels_t5[:cut_off]),\n",
    "                 batch_size=16,\n",
    "                epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great! It learned, and the test accuracies are well into the 90% range!  But be careful... the metrics above have been achieved with **teacher-forcing**. In actual inference mode where you do not force the correct input at each decoder time-step, but instead generate the the NER-token step by step, any error will affect the next prediction. This will likely increase the error rate noticeably.\n",
    "\n",
    "For now, we leave it as an exercise to the reader to write the corresponding inference loop (using past key values, etc.) and to compare the results using T5 with the those of the BERT model quoted earlier in this paper. \n",
    "\n",
    "But either way, the main point is established: the architecture learns reasonably well and the results are far from random. And most importantly, we hope that these steps help you to **get started with T5.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
